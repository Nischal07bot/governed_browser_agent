Sentinel Agent Runtime

A governed AI execution runtime for regulated browser workflows

Sentinel Agent Runtime is an enterprise-grade managed AI browser agent platform that enables organizations to safely deploy AI agents inside the browser without sacrificing security, auditability, or policy control.

Unlike consumer AI extensions, Sentinel is designed for regulated environments (finance, compliance, internal ops), where every AI action must be explainable, enforceable, and auditable.

ğŸš¨ The Problem

Organizations want to use AI agents to automate browser-based workflows (e.g. invoice processing, internal portals, dashboards), but:

âŒ AI browser agents can leak sensitive data

âŒ No enforceable enterprise policies

âŒ No audit trail or replayability

âŒ No role-based or domain-based restrictions

As a result, security teams ban AI agents entirely, forcing employees back to manual work.

âœ… The Solution

Sentinel Agent Runtime introduces a governed AI execution model:

AI agents can act inside the browser

But only within admin-defined policies

Every action is logged, validated, and auditable

Execution happens locally in the browser

Governance and reasoning happen server-side

Execution is sandboxed. Intelligence is controlled. Trust is enforced.

ğŸ¯ MVP Scope (Frozen)

This repository implements a focused MVP for a finance operations workflow:

Extract invoice totals and vendor names from a web-based invoice portal using a policy-aware AI agent.

What the MVP Includes

Chrome extension that executes agent steps in the browser

Backend agent orchestrator with policy enforcement

Structured AI planning (no free-form execution)

Immutable audit logging for every agent action

Admin-defined policy via configuration

Explicitly Out of Scope (by design)

Consumer AI chat UX

Multiple workflows

Policy UI (config-only for MVP)

Human approval mid-execution

Multi-tenant billing

LLM experimentation playground

This restraint is intentional and mirrors real enterprise systems.

ğŸ§  Core Design Principles
1. Policy First

AI agents never reason or act outside policy boundaries.
Policies are enforced at:

Plan generation time

Step execution time

Data extraction time

2. Execution in the Browser

All DOM access and page interaction happen locally inside the browser extension to:

Preserve same-origin guarantees

Prevent raw data exfiltration

Reduce backend blast radius

3. Structured Agent Execution

Agents operate on explicit, typed steps, not free-form actions.

{
  "action": "EXTRACT_FIELD",
  "field": "invoice_total"
}

4. Auditability by Default

Every agent action emits an immutable audit event:

What happened

Why it happened

Whether it was allowed or blocked

ğŸ—ï¸ High-Level Architecture
Browser Extension (Execution Plane)
        â”‚
        â”‚ Secure RPC
        â–¼
Agent Gateway (Auth & Rate Limiting)
        â”‚
        â–¼
Policy Engine (Enforcement)
        â”‚
        â–¼
Agent Orchestrator (Planning)
        â”‚
        â–¼
Audit Log Service (Append-only)


Key separation:

Execution Plane â†’ Browser

Control Plane â†’ Backend

ğŸ” Policy Model (MVP)

Policies are declarative and enforced at runtime.

allowed_domains:
  - invoices.example.com

allowed_actions:
  - READ_TABLE
  - EXTRACT_FIELD

allowed_fields:
  - vendor_name
  - invoice_total

max_steps: 10


If a policy is violated, execution is immediately terminated and logged.

ğŸ“œ Audit Logging

Every agent interaction produces an append-only audit event.

{
  "timestamp": "2026-01-16T10:12:30Z",
  "actor": "agent",
  "action": "EXTRACT_FIELD",
  "field": "invoice_total",
  "status": "allowed",
  "page_hash": "abc123"
}


This enables:

Compliance audits

Post-incident analysis

Replayable execution (future work)

ğŸ§± Repository Structure
sentinel-agent-runtime/
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ agent-loop.md
â”‚   â”œâ”€â”€ policy-model.md
â”‚   â””â”€â”€ threat-model.md
â”‚
â”œâ”€â”€ extension/
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ background/
â”‚   â”œâ”€â”€ content/
â”‚   â”œâ”€â”€ ui/
â”‚   â””â”€â”€ shared/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â”œâ”€â”€ gateway/
â”‚   â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â””â”€â”€ auditor/
â”‚   â”œâ”€â”€ internal/
â”‚   â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ policy/
â”‚   â”‚   â”œâ”€â”€ audit/
â”‚   â”‚   â””â”€â”€ auth/
â”‚   â””â”€â”€ pkg/
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ policy.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ dev.sh
â”‚
â””â”€â”€ Makefile

ğŸ› ï¸ Tech Stack
Browser Extension

TypeScript

Chrome Extension Manifest V3

Content scripts + background service worker

Backend

Go (deterministic, infra-grade)

JSON-over-HTTPS / gRPC

PostgreSQL (metadata)

Object storage (audit logs)

AI

Single planner model

Strict JSON schema output

No chain-of-thought storage

ğŸ§ª Current Status

ğŸš§ Active Development â€” MVP Phase

 Extension â†’ backend communication

 Agent planning loop

 Policy enforcement

 Audit log persistence

ğŸ§  Why This Project Exists

This project is intentionally designed to explore:

AI governance

Secure agent execution

Browser-based enforcement

Enterprise auditability

It reflects real-world constraints faced by companies deploying AI in regulated environments.



If you are reviewing this repo

Start with:

docs/architecture.md

docs/agent-loop.md

docs/threat-model.md